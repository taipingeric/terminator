{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('dataset/raw/polyA_cs.fasta') as f:\n",
    "#     lines = f.readlines()\n",
    "#     for line in lines[:2]:\n",
    "#         print(line)\n",
    "#     print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in /opt/conda/lib/python3.6/site-packages (0.22.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "from textwrap import dedent\n",
    "from time import strftime\n",
    "from itertools import product\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Embedding, Bidirectional, Flatten, Dropout, GRU, Input, Conv1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for bases\n",
    "classes = {'A': 0,  # 0001\n",
    "         'T': 1,  # 0010\n",
    "         'C': 2,  # 0100\n",
    "         'G': 3,  # 1000 \n",
    "        }\n",
    "\n",
    "def fasta_to_vectors(in_fasta):\n",
    "    with open(in_fasta) as f:\n",
    "        header_seq = f.readlines()\n",
    "    \n",
    "    seq = [header_seq[i * 2 + 1].strip().upper() for i in range(int(len(header_seq)/2))] # extract seq data only\n",
    "    print(np.array(seq).shape)\n",
    "    for s in seq:\n",
    "        assert len(s) == 200\n",
    "        continue\n",
    "    \n",
    "    seqs = np.zeros((len(seq), 200, 1))\n",
    "    for i, s in enumerate(seq):\n",
    "        for j, char in enumerate(s):\n",
    "            seqs[i, j] = classes[char]\n",
    "    output = to_categorical(seqs, num_classes=len(classes))\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52457,)\n",
      "(27595,)\n",
      "(52460,)\n"
     ]
    }
   ],
   "source": [
    "lab1_fasta = '../dataset/raw/polyA_cs.fasta' # args.polya\n",
    "lab2_fasta = '../dataset/raw/non-polyA_cs.fasta' # args.cs\n",
    "lab3_fasta = '../dataset/raw/non-cs.fasta'\n",
    "l = 200\n",
    "\n",
    "k = np.array([4, 6, 8, 10])\n",
    "\n",
    "seq_vector_lab1 = np.array(fasta_to_vectors(lab1_fasta))\n",
    "seq_vector_lab2 = np.array(fasta_to_vectors(lab2_fasta))\n",
    "seq_vector_lab3 = np.array(fasta_to_vectors(lab3_fasta))\n",
    "lab_vector_lab1 = np.tile([1, 0, 0], (len(seq_vector_lab1), 1))\n",
    "lab_vector_lab2 = np.tile([0, 1, 0], (len(seq_vector_lab2), 1))\n",
    "lab_vector_lab3 = np.tile([0, 0, 1], (len(seq_vector_lab3), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the whole model\n",
    "random.seed(123)\n",
    "\n",
    "size1 = len(seq_vector_lab1)\n",
    "size2 = len(seq_vector_lab2)\n",
    "size3 = len(seq_vector_lab3)\n",
    "\n",
    "if size1 != size2 or size1 != size3:\n",
    "    train_i1 = random.sample(range(size1), int(0.7 * size1))\n",
    "    train_i2 = random.sample(range(size2), int(0.7 * size2))\n",
    "    train_i3 = random.sample(range(size3), int(0.7 * size3))\n",
    "\n",
    "else:\n",
    "    train_i1 = random.sample(range(size1), int(0.7 * size1))\n",
    "    train_i2 = train_i1\n",
    "    train_i3 = train_i1\n",
    "\n",
    "test_val1 = [i for i in range(size1) if i not in train_i1]\n",
    "val_i1 = random.sample(test_val1, int(0.2 * size1))\n",
    "\n",
    "test_val2 = [i for i in range(size2) if i not in train_i2]\n",
    "val_i2 = random.sample(test_val2, int(0.2 * size2))\n",
    "\n",
    "test_val3 = [i for i in range(size3) if i not in train_i3]\n",
    "val_i3 = random.sample(test_val3, int(0.2 * size3))\n",
    "\n",
    "x_train = np.concatenate((seq_vector_lab1[train_i1], seq_vector_lab2[train_i2], seq_vector_lab3[train_i3]))\n",
    "y_train = np.concatenate((lab_vector_lab1[train_i1], lab_vector_lab2[train_i2], lab_vector_lab3[train_i3]))\n",
    "x_val = np.concatenate((seq_vector_lab1[val_i1], seq_vector_lab2[val_i2], seq_vector_lab3[val_i3]))\n",
    "y_val = np.concatenate((lab_vector_lab1[val_i1], lab_vector_lab2[val_i2], lab_vector_lab3[val_i3]))\n",
    "\n",
    "#     sys.stdout.write(strftime(\"%Y-%m-%d %H:%M:%S\") + \": Start training\\n\")\n",
    "#     sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92757, 200, 4) (92757, 3) (26502, 200, 4) (26502, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(weights=''):\n",
    "    #activation = keras.layers.LeakyReLU(alpha=0.3)\n",
    "#     def activation(x):\n",
    "#         return keras.activations.relu(x)\n",
    "    activation = 'relu'\n",
    "    ssInput = Input(shape = (200, len(classes)))\n",
    "    ssConv = Conv1D(filters=256,\n",
    "                    kernel_size=12,\n",
    "                    padding = \"valid\",\n",
    "                    activation=activation,\n",
    "                    strides=1)(ssInput)\n",
    "#     ssConv = activation(ssConv)\n",
    "    ssPool = AveragePooling1D(pool_size = 5, strides = 5)(ssConv)\n",
    "    ssDout1 = Dropout(rate=0.5)(ssPool)\n",
    "    seqBiLstm = Bidirectional(LSTM(units = 128, return_sequences = True))(ssDout1)\n",
    "    seqDout2 = Dropout(rate = 0.5)(seqBiLstm)\n",
    "    ssFlat = Flatten()(seqDout2)\n",
    "    ssDen1 = Dense(256, kernel_initializer='glorot_uniform', activation=activation)(ssFlat)\n",
    "#     ssDen1 = activation(ssDen1)\n",
    "    ssDout2 = Dropout(rate=0.5)(ssDen1)\n",
    "    den2 = Dense(256, kernel_initializer = 'glorot_uniform', activation='relu')(ssDout2)\n",
    "#     den2 = activation(den2)\n",
    "    dout2 = Dropout(rate = 0.5)(den2)\n",
    "    den3 = Dense(256, activation='relu')(dout2)\n",
    "#     dens = activation(den3)\n",
    "    den4 = Dense(3, activation = 'softmax')(den3)\n",
    "    model = Model(inputs = ssInput, outputs = den4)\n",
    "\n",
    "\n",
    "\n",
    "    adam = optimizers.Adam(lr=0.001)\n",
    "\n",
    "    if weights:\n",
    "        model.load_weights(weights)\n",
    "        print(\"Created model and loaded weights from file: \", weights)\n",
    "    else:\n",
    "        print(model.summary())\n",
    "        print(\"adam: 0.001\", )\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=adam,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200, 4)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 189, 256)          12544     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 37, 256)           394240    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9472)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2425088   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 2,964,227\n",
      "Trainable params: 2,964,227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "adam: 0.001\n",
      "Train on 92757 samples, validate on 26502 samples\n",
      "Epoch 1/100\n",
      "92757/92757 [==============================] - 79s 850us/step - loss: 0.6897 - acc: 0.7046 - val_loss: 0.6027 - val_acc: 0.7415\n",
      "Epoch 2/100\n",
      "92757/92757 [==============================] - 75s 808us/step - loss: 0.5944 - acc: 0.7467 - val_loss: 0.5580 - val_acc: 0.7645\n",
      "Epoch 3/100\n",
      "92757/92757 [==============================] - 75s 808us/step - loss: 0.5639 - acc: 0.7594 - val_loss: 0.5317 - val_acc: 0.7762\n",
      "Epoch 4/100\n",
      "92757/92757 [==============================] - 75s 807us/step - loss: 0.5462 - acc: 0.7655 - val_loss: 0.5246 - val_acc: 0.7753\n",
      "Epoch 5/100\n",
      "92757/92757 [==============================] - 75s 807us/step - loss: 0.5348 - acc: 0.7713 - val_loss: 0.5257 - val_acc: 0.7744\n",
      "Epoch 6/100\n",
      "92757/92757 [==============================] - 75s 810us/step - loss: 0.5247 - acc: 0.7760 - val_loss: 0.5165 - val_acc: 0.7851\n",
      "Epoch 7/100\n",
      "92757/92757 [==============================] - 75s 807us/step - loss: 0.5174 - acc: 0.7798 - val_loss: 0.5011 - val_acc: 0.7858\n",
      "Epoch 8/100\n",
      "92757/92757 [==============================] - 75s 806us/step - loss: 0.5084 - acc: 0.7827 - val_loss: 0.4935 - val_acc: 0.7891\n",
      "Epoch 9/100\n",
      "92757/92757 [==============================] - 75s 808us/step - loss: 0.5034 - acc: 0.7864 - val_loss: 0.4950 - val_acc: 0.7914\n",
      "Epoch 10/100\n",
      "92757/92757 [==============================] - 75s 807us/step - loss: 0.4979 - acc: 0.7884 - val_loss: 0.4964 - val_acc: 0.7904\n",
      "Epoch 11/100\n",
      "92757/92757 [==============================] - 75s 807us/step - loss: 0.4932 - acc: 0.7907 - val_loss: 0.4884 - val_acc: 0.7905\n",
      "Epoch 12/100\n",
      "92757/92757 [==============================] - 75s 811us/step - loss: 0.4856 - acc: 0.7941 - val_loss: 0.4943 - val_acc: 0.7888\n",
      "Epoch 13/100\n",
      "92757/92757 [==============================] - 75s 807us/step - loss: 0.4805 - acc: 0.7956 - val_loss: 0.4904 - val_acc: 0.7937\n",
      "Epoch 14/100\n",
      "92757/92757 [==============================] - 75s 807us/step - loss: 0.4773 - acc: 0.7974 - val_loss: 0.4778 - val_acc: 0.7983\n",
      "Epoch 15/100\n",
      "92757/92757 [==============================] - 75s 807us/step - loss: 0.4710 - acc: 0.8012 - val_loss: 0.4766 - val_acc: 0.7974\n",
      "Epoch 16/100\n",
      "92757/92757 [==============================] - 75s 807us/step - loss: 0.4657 - acc: 0.8022 - val_loss: 0.4751 - val_acc: 0.7976\n",
      "Epoch 17/100\n",
      "92757/92757 [==============================] - 75s 810us/step - loss: 0.4625 - acc: 0.8039 - val_loss: 0.4782 - val_acc: 0.7940\n",
      "Epoch 18/100\n",
      "92757/92757 [==============================] - 75s 809us/step - loss: 0.4586 - acc: 0.8048 - val_loss: 0.4776 - val_acc: 0.7956\n",
      "Epoch 19/100\n",
      "92757/92757 [==============================] - 75s 808us/step - loss: 0.4537 - acc: 0.8073 - val_loss: 0.4748 - val_acc: 0.7992\n",
      "Epoch 20/100\n",
      "92757/92757 [==============================] - 75s 808us/step - loss: 0.4469 - acc: 0.8085 - val_loss: 0.4772 - val_acc: 0.7964\n",
      "Epoch 21/100\n",
      "92757/92757 [==============================] - 75s 809us/step - loss: 0.4427 - acc: 0.8121 - val_loss: 0.4754 - val_acc: 0.8005\n",
      "Epoch 22/100\n",
      "92757/92757 [==============================] - 75s 810us/step - loss: 0.4389 - acc: 0.8130 - val_loss: 0.4737 - val_acc: 0.7996\n",
      "Epoch 23/100\n",
      "92757/92757 [==============================] - 75s 809us/step - loss: 0.4374 - acc: 0.8143 - val_loss: 0.4690 - val_acc: 0.8001\n",
      "Epoch 24/100\n",
      "92757/92757 [==============================] - 75s 808us/step - loss: 0.4314 - acc: 0.8168 - val_loss: 0.4742 - val_acc: 0.8005\n",
      "Epoch 25/100\n",
      "92757/92757 [==============================] - 75s 805us/step - loss: 0.4275 - acc: 0.8179 - val_loss: 0.4673 - val_acc: 0.8016\n",
      "Epoch 26/100\n",
      "92757/92757 [==============================] - 75s 808us/step - loss: 0.4233 - acc: 0.8203 - val_loss: 0.4680 - val_acc: 0.8029\n",
      "Epoch 27/100\n",
      "92757/92757 [==============================] - 75s 807us/step - loss: 0.4196 - acc: 0.8192 - val_loss: 0.4715 - val_acc: 0.8013\n",
      "Epoch 28/100\n",
      "92757/92757 [==============================] - 75s 809us/step - loss: 0.4155 - acc: 0.8230 - val_loss: 0.4694 - val_acc: 0.8007\n",
      "Epoch 29/100\n",
      "92757/92757 [==============================] - 75s 808us/step - loss: 0.4120 - acc: 0.8242 - val_loss: 0.4693 - val_acc: 0.8016\n",
      "Epoch 30/100\n",
      "92757/92757 [==============================] - 75s 806us/step - loss: 0.4075 - acc: 0.8267 - val_loss: 0.4710 - val_acc: 0.8010\n",
      "Epoch 31/100\n",
      "92757/92757 [==============================] - 75s 808us/step - loss: 0.4026 - acc: 0.8298 - val_loss: 0.4775 - val_acc: 0.7998\n",
      "Epoch 32/100\n",
      "92757/92757 [==============================] - 75s 806us/step - loss: 0.4002 - acc: 0.8283 - val_loss: 0.4705 - val_acc: 0.8013\n",
      "Epoch 33/100\n",
      "92757/92757 [==============================] - 75s 807us/step - loss: 0.3969 - acc: 0.8315 - val_loss: 0.4787 - val_acc: 0.7999\n",
      "Epoch 34/100\n",
      "92757/92757 [==============================] - 75s 808us/step - loss: 0.3937 - acc: 0.8321 - val_loss: 0.4749 - val_acc: 0.7997\n",
      "Epoch 35/100\n",
      "92757/92757 [==============================] - 75s 809us/step - loss: 0.3882 - acc: 0.8342 - val_loss: 0.4717 - val_acc: 0.8007\n"
     ]
    }
   ],
   "source": [
    "weight_file = ''\n",
    "model = create_model()\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
    "filepath = weight_file + \"terminator.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True)\n",
    "\n",
    "# load pretrained\n",
    "# model = load_model('terminator.hdf5')\n",
    "\n",
    "logs = model.fit(x_train, y_train, batch_size=128, verbose=1, epochs=100,\n",
    "          validation_data=(x_val, y_val),\n",
    "          callbacks=[checkpoint, early_stop])\n",
    "    \n",
    "#     sys.stdout.write(strftime(\"%Y-%m-%d %H:%M:%S\") + \": Finished!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loss: 0.4679 - val_acc: 0.8073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('terminator.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200, 4)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 189, 256)          12544     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 37, 256)           394240    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9472)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2425088   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 2,964,227\n",
      "Trainable params: 2,964,227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26502, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26502, 200, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     10491\n",
      "           1       0.69      0.30      0.42      5519\n",
      "           2       0.72      0.91      0.80     10492\n",
      "\n",
      "    accuracy                           0.80     26502\n",
      "   macro avg       0.78      0.72      0.72     26502\n",
      "weighted avg       0.79      0.80      0.78     26502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val)\n",
    "print(classification_report(np.argmax(y_val, axis=-1), np.argmax(y_pred, axis=-1), target_names=[str(i) for i in range(3)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10073    92   326]\n",
      " [  522  1663  3334]\n",
      " [  323   660  9509]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(np.argmax(y_val, axis=-1), np.argmax(y_pred, axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label = np.argmax(y_pred, axis=-1)\n",
    "y_val_label = np.argmax(y_val, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label[y_pred_label > 0] = 1\n",
    "y_val_label[y_val_label > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label = 1 - y_pred_label\n",
    "y_val_label = 1- y_val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96     16011\n",
      "           1       0.92      0.96      0.94     10491\n",
      "\n",
      "    accuracy                           0.95     26502\n",
      "   macro avg       0.95      0.95      0.95     26502\n",
      "weighted avg       0.95      0.95      0.95     26502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val_label, y_pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26502,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_label.shape, \n",
    "y_val_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivy(y_pred, y_true):\n",
    "    CM = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    return TP / (FN + TP)\n",
    "def acc(y_pred, y_true):\n",
    "    CM = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    \n",
    "    return sklearn.metrics.accuracy_score(y_true, y_pred), (TP + TN) / (TP + TN + FN + FP)\n",
    "def specificity(y_pred, y_true):\n",
    "    CM = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    return TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9523432193796695, 0.9523432193796695)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(y_pred_label, y_val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9601563244685921"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivy(y_pred_label, y_val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9472237836487415"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specificity(y_pred_label, y_val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
