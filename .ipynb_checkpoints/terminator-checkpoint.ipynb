{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('dataset/raw/polyA_cs.fasta') as f:\n",
    "#     lines = f.readlines()\n",
    "#     for line in lines[:2]:\n",
    "#         print(line)\n",
    "#     print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in /opt/conda/lib/python3.6/site-packages (0.22.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "from textwrap import dedent\n",
    "from time import strftime\n",
    "from itertools import product\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Embedding, Bidirectional, Flatten, Dropout, GRU\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1118464\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b01d132f144e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0mseq_vector_lab1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfasta_to_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlab1_fasta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0mseq_vector_lab2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfasta_to_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlab2_fasta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mseq_vector_lab3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfasta_to_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlab3_fasta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-b01d132f144e>\u001b[0m in \u001b[0;36mfasta_to_vectors\u001b[0;34m(in_fasta, k_list)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmer_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mseq_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mone_hot_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmer_encoding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mseq_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-b01d132f144e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmer_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mseq_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mone_hot_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmer_encoding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mseq_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-b01d132f144e>\u001b[0m in \u001b[0;36mone_hot_encoding\u001b[0;34m(seq, k_list, kmer_encoding)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mk_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mkmer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mencoded_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk_i\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmer_encoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkmer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mencoded_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# One hot encoding for bases\n",
    "BASES = {'A': 0,  # 0001\n",
    "         'C': 1,  # 0010\n",
    "         'G': 2,  # 0100\n",
    "         'T': 3,  # 1000\n",
    "         'a': 0,\n",
    "         'c': 1,\n",
    "         'g': 2,\n",
    "         't': 3}\n",
    "VERSION = 'v0.0.1'\n",
    "\n",
    "\n",
    "def one_hot_encoding(seq, k_list, kmer_encoding):\n",
    "    encoded_list = np.zeros(len(seq) * len(k_list) - sum(k_list) + len(k_list)) # 200 * 4 - sum(4,6,8,10) + 4\n",
    "    seq = seq.upper()\n",
    "    for k_i in range(len(k_list)):\n",
    "        for i in range(len(seq) - k_list[k_i] + 1):\n",
    "            kmer = seq[i: i + k_list[k_i]]\n",
    "            encoded_list[i + len(seq) * k_i - sum(k_list[:k_i]) + k_i] = kmer_encoding[kmer]\n",
    "    return encoded_list\n",
    "\n",
    "\n",
    "def fasta_to_vectors(in_fasta, k_list):\n",
    "    with open(in_fasta) as f:\n",
    "        header_seq = f.readlines()\n",
    "    \n",
    "    seq = [header_seq[i * 2 + 1].strip() for i in range(int(len(header_seq)/2))] # extract seq data only\n",
    "\n",
    "    # Generate all unique kmers and their one hot encoding\n",
    "    unique_kmers = sum(pow(4, k_list)) # sum(4^ [4, 6, 8, 10])\n",
    "    all_kmers = []\n",
    "    for k in k_list:\n",
    "        # AAAA, AAAT, AAAC, AAAG, GGGG k = 4\n",
    "        # ..., GGGGGGGGGG, k = 10\n",
    "        all_kmers.extend(list(product(['A', 'T', 'C', 'G'], repeat=k))) \n",
    "\n",
    "    all_kmers = [''.join(x) for x in all_kmers] # AAAA ~ GGGGGGGGGG\n",
    "    kmer_encoding = dict(zip(all_kmers, range(unique_kmers))) # unique kmers: 1118464\n",
    "\n",
    "    seq_vector = [one_hot_encoding(x, k_list, kmer_encoding) for x in seq]\n",
    "    return seq_vector\n",
    "\n",
    "\n",
    "def create_model(l, k, weights=''):\n",
    "    model = Sequential()\n",
    "    length = l * len(k) - sum(k) + len(k)\n",
    "    model.add(Embedding(sum(pow(4, k)), 128, input_length=length))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    adam = optimizers.Adam(lr=0.001)\n",
    "\n",
    "    if weights:\n",
    "        model.load_weights(weights)\n",
    "        print(\"Created model and loaded weights from file: \", weights)\n",
    "    else:\n",
    "        print(model.summary())\n",
    "        print(\"adam: 0.001\", )\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=adam,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "lab1_fasta = '../dataset/raw/polyA_cs.fasta' # args.polya\n",
    "lab2_fasta = '../dataset/raw/non-polyA_cs.fasta' # args.cs\n",
    "lab3_fasta = '../dataset/raw/non-cs.fasta'\n",
    "l = 200\n",
    "\n",
    "k = np.array([4, 6, 8, 10])\n",
    "\n",
    "seq_vector_lab1 = np.array(fasta_to_vectors(lab1_fasta, k))\n",
    "seq_vector_lab2 = np.array(fasta_to_vectors(lab2_fasta, k))\n",
    "seq_vector_lab3 = np.array(fasta_to_vectors(lab3_fasta, k))\n",
    "lab_vector_lab1 = np.tile([1, 0, 0], (len(seq_vector_lab1), 1))\n",
    "lab_vector_lab2 = np.tile([0, 1, 0], (len(seq_vector_lab2), 1))\n",
    "lab_vector_lab3 = np.tile([0, 0, 1], (len(seq_vector_lab3), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the whole model\n",
    "random.seed(123)\n",
    "\n",
    "size1 = len(seq_vector_lab1)\n",
    "size2 = len(seq_vector_lab2)\n",
    "size3 = len(seq_vector_lab3)\n",
    "\n",
    "if size1 != size2 or size1 != size3:\n",
    "    train_i1 = random.sample(range(size1), int(0.7 * size1))\n",
    "    train_i2 = random.sample(range(size2), int(0.7 * size2))\n",
    "    train_i3 = random.sample(range(size3), int(0.7 * size3))\n",
    "\n",
    "else:\n",
    "    train_i1 = random.sample(range(size1), int(0.7 * size1))\n",
    "    train_i2 = train_i1\n",
    "    train_i3 = train_i1\n",
    "\n",
    "test_val1 = [i for i in range(size1) if i not in train_i1]\n",
    "val_i1 = random.sample(test_val1, int(0.2 * size1))\n",
    "\n",
    "test_val2 = [i for i in range(size2) if i not in train_i2]\n",
    "val_i2 = random.sample(test_val2, int(0.2 * size2))\n",
    "\n",
    "test_val3 = [i for i in range(size3) if i not in train_i3]\n",
    "val_i3 = random.sample(test_val3, int(0.2 * size3))\n",
    "\n",
    "x_train = np.concatenate((seq_vector_lab1[train_i1], seq_vector_lab2[train_i2], seq_vector_lab3[train_i3]))\n",
    "y_train = np.concatenate((lab_vector_lab1[train_i1], lab_vector_lab2[train_i2], lab_vector_lab3[train_i3]))\n",
    "x_val = np.concatenate((seq_vector_lab1[val_i1], seq_vector_lab2[val_i2], seq_vector_lab3[val_i3]))\n",
    "y_val = np.concatenate((lab_vector_lab1[val_i1], lab_vector_lab2[val_i2], lab_vector_lab3[val_i3]))\n",
    "\n",
    "#     sys.stdout.write(strftime(\"%Y-%m-%d %H:%M:%S\") + \": Start training\\n\")\n",
    "#     sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 776, 128)          143163392 \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 99328)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               50856448  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 194,054,851\n",
      "Trainable params: 194,054,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "adam: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 143163392 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92757 samples, validate on 26502 samples\n",
      "Epoch 1/100\n",
      "92757/92757 [==============================] - 147s 2ms/step - loss: 0.5285 - acc: 0.7781 - val_loss: 0.4664 - val_acc: 0.8061\n",
      "Epoch 2/100\n",
      "92757/92757 [==============================] - 135s 1ms/step - loss: 0.0214 - acc: 0.9941 - val_loss: 0.7624 - val_acc: 0.7731\n",
      "Epoch 3/100\n",
      "92757/92757 [==============================] - 135s 1ms/step - loss: 0.0075 - acc: 0.9989 - val_loss: 0.8212 - val_acc: 0.7567\n",
      "Epoch 4/100\n",
      "92757/92757 [==============================] - 135s 1ms/step - loss: 0.0087 - acc: 0.9984 - val_loss: 1.4185 - val_acc: 0.7320\n",
      "Epoch 5/100\n",
      "92757/92757 [==============================] - 134s 1ms/step - loss: 0.0097 - acc: 0.9984 - val_loss: 1.3417 - val_acc: 0.7473\n",
      "Epoch 6/100\n",
      "92757/92757 [==============================] - 135s 1ms/step - loss: 0.0073 - acc: 0.9990 - val_loss: 2.0066 - val_acc: 0.7342\n",
      "Epoch 7/100\n",
      "92757/92757 [==============================] - 135s 1ms/step - loss: 0.0089 - acc: 0.9988 - val_loss: 1.1889 - val_acc: 0.7556\n",
      "Epoch 8/100\n",
      "92757/92757 [==============================] - 135s 1ms/step - loss: 0.0077 - acc: 0.9992 - val_loss: 1.7469 - val_acc: 0.7625\n",
      "Epoch 9/100\n",
      "92757/92757 [==============================] - 135s 1ms/step - loss: 0.0076 - acc: 0.9993 - val_loss: 1.5205 - val_acc: 0.7595\n",
      "Epoch 10/100\n",
      "92757/92757 [==============================] - 135s 1ms/step - loss: 0.0094 - acc: 0.9990 - val_loss: 1.4847 - val_acc: 0.7515\n",
      "Epoch 11/100\n",
      "92757/92757 [==============================] - 135s 1ms/step - loss: 0.0091 - acc: 0.9990 - val_loss: 1.9798 - val_acc: 0.7535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe6300fed68>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_file = ''\n",
    "model = create_model(l, k)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
    "filepath = weight_file + \"terminator.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True)\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=64, verbose=1, epochs=100,\n",
    "          validation_data=(x_val, y_val),\n",
    "          callbacks=[checkpoint, early_stop])\n",
    "    \n",
    "#     sys.stdout.write(strftime(\"%Y-%m-%d %H:%M:%S\") + \": Finished!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loss: 0.4679 - val_acc: 0.8073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 143163392 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    }
   ],
   "source": [
    "model = load_model('terminator-0.4679.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 776, 128)          143163392 \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 99328)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               50856448  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 194,054,851\n",
      "Trainable params: 194,054,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26502, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26502, 776)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.94     10491\n",
      "           1       0.78      0.31      0.44      5519\n",
      "           2       0.72      0.92      0.81     10492\n",
      "\n",
      "    accuracy                           0.81     26502\n",
      "   macro avg       0.81      0.73      0.73     26502\n",
      "weighted avg       0.81      0.81      0.78     26502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val)\n",
    "print(classification_report(np.argmax(y_val, axis=-1), np.argmax(y_pred, axis=-1), target_names=[str(i) for i in range(3)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10061    60   370]\n",
      " [  488  1712  3319]\n",
      " [  449   420  9623]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(np.argmax(y_val, axis=-1), np.argmax(y_pred, axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label = np.argmax(y_pred, axis=-1)\n",
    "y_val_label = np.argmax(y_val, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label[y_pred_label > 0] = 1\n",
    "y_val_label[y_val_label > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label = 1 - y_pred_label\n",
    "y_val_label = 1- y_val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96     16011\n",
      "           1       0.91      0.96      0.94     10491\n",
      "\n",
      "    accuracy                           0.95     26502\n",
      "   macro avg       0.94      0.95      0.95     26502\n",
      "weighted avg       0.95      0.95      0.95     26502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val_label, y_pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26502,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_label.shape, \n",
    "y_val_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivy(y_pred, y_true):\n",
    "    CM = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    return TP / (FN + TP)\n",
    "def acc(y_pred, y_true):\n",
    "    CM = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    \n",
    "    return sklearn.metrics.accuracy_score(y_true, y_pred), (TP + TN) / (TP + TN + FN + FP)\n",
    "def specificity(y_pred, y_true):\n",
    "    CM = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    return TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9484189872462455, 0.9484189872462455)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(y_pred_label, y_val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9590124868935278"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivy(y_pred_label, y_val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f5bf50d8cd57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspecificity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred_label' is not defined"
     ]
    }
   ],
   "source": [
    "specificity(y_pred_label, y_val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
