{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('dataset/raw/polyA_cs.fasta') as f:\n",
    "#     lines = f.readlines()\n",
    "#     for line in lines[:2]:\n",
    "#         print(line)\n",
    "#     print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in /opt/conda/lib/python3.6/site-packages (0.22.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "from textwrap import dedent\n",
    "from time import strftime\n",
    "from itertools import product\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Embedding, Bidirectional, Flatten, Dropout, GRU, Input, Conv1D, AveragePooling1D, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for bases\n",
    "classes = {'A': 0,  # 0001\n",
    "         'T': 1,  # 0010\n",
    "         'C': 2,  # 0100\n",
    "         'G': 3,  # 1000 \n",
    "        }\n",
    "\n",
    "def fasta_to_vectors(in_fasta):\n",
    "    with open(in_fasta) as f:\n",
    "        header_seq = f.readlines()\n",
    "    \n",
    "    seq = [header_seq[i * 2 + 1].strip().upper() for i in range(int(len(header_seq)/2))] # extract seq data only\n",
    "    print(np.array(seq).shape)\n",
    "    for s in seq:\n",
    "        assert len(s) == 200\n",
    "        continue\n",
    "    \n",
    "    seqs = np.zeros((len(seq), 200, 1))\n",
    "    for i, s in enumerate(seq):\n",
    "        for j, char in enumerate(s):\n",
    "            seqs[i, j] = classes[char]\n",
    "    output = to_categorical(seqs, num_classes=len(classes))\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52457,)\n",
      "(27595,)\n",
      "(52460,)\n"
     ]
    }
   ],
   "source": [
    "lab1_fasta = '../dataset/raw/polyA_cs.fasta' # args.polya\n",
    "lab2_fasta = '../dataset/raw/non-polyA_cs.fasta' # args.cs\n",
    "lab3_fasta = '../dataset/raw/non-cs.fasta'\n",
    "l = 200\n",
    "\n",
    "k = np.array([4, 6, 8, 10])\n",
    "\n",
    "seq_vector_lab1 = np.array(fasta_to_vectors(lab1_fasta))\n",
    "seq_vector_lab2 = np.array(fasta_to_vectors(lab2_fasta))\n",
    "seq_vector_lab3 = np.array(fasta_to_vectors(lab3_fasta))\n",
    "lab_vector_lab1 = np.tile([1, 0, 0], (len(seq_vector_lab1), 1))\n",
    "lab_vector_lab2 = np.tile([0, 1, 0], (len(seq_vector_lab2), 1))\n",
    "lab_vector_lab3 = np.tile([0, 0, 1], (len(seq_vector_lab3), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the whole model\n",
    "random.seed(123)\n",
    "\n",
    "size1 = len(seq_vector_lab1)\n",
    "size2 = len(seq_vector_lab2)\n",
    "size3 = len(seq_vector_lab3)\n",
    "\n",
    "if size1 != size2 or size1 != size3:\n",
    "    train_i1 = random.sample(range(size1), int(0.7 * size1))\n",
    "    train_i2 = random.sample(range(size2), int(0.7 * size2))\n",
    "    train_i3 = random.sample(range(size3), int(0.7 * size3))\n",
    "\n",
    "else:\n",
    "    train_i1 = random.sample(range(size1), int(0.7 * size1))\n",
    "    train_i2 = train_i1\n",
    "    train_i3 = train_i1\n",
    "\n",
    "test_val1 = [i for i in range(size1) if i not in train_i1]\n",
    "val_i1 = random.sample(test_val1, int(0.2 * size1))\n",
    "\n",
    "test_val2 = [i for i in range(size2) if i not in train_i2]\n",
    "val_i2 = random.sample(test_val2, int(0.2 * size2))\n",
    "\n",
    "test_val3 = [i for i in range(size3) if i not in train_i3]\n",
    "val_i3 = random.sample(test_val3, int(0.2 * size3))\n",
    "\n",
    "x_train = np.concatenate((seq_vector_lab1[train_i1], seq_vector_lab2[train_i2], seq_vector_lab3[train_i3]))\n",
    "y_train = np.concatenate((lab_vector_lab1[train_i1], lab_vector_lab2[train_i2], lab_vector_lab3[train_i3]))\n",
    "x_val = np.concatenate((seq_vector_lab1[val_i1], seq_vector_lab2[val_i2], seq_vector_lab3[val_i3]))\n",
    "y_val = np.concatenate((lab_vector_lab1[val_i1], lab_vector_lab2[val_i2], lab_vector_lab3[val_i3]))\n",
    "\n",
    "#     sys.stdout.write(strftime(\"%Y-%m-%d %H:%M:%S\") + \": Start training\\n\")\n",
    "#     sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92757, 200, 4) (92757, 3) (26502, 200, 4) (26502, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(weights=''):\n",
    "    #activation = keras.layers.LeakyReLU(alpha=0.3)\n",
    "#     def activation(x):\n",
    "#         return keras.activations.relu(x)\n",
    "    activation = 'relu'\n",
    "    ssInput = Input(shape = (200, len(classes)))\n",
    "    ssConv = Conv1D(filters=256,\n",
    "                    kernel_size=12,\n",
    "                    padding = \"valid\",\n",
    "                    activation=activation,\n",
    "                    strides=1)(ssInput)\n",
    "    ssConv = BatchNormalization()(ssConv)\n",
    "    ssPool = AveragePooling1D(pool_size = 5, strides = 5)(ssConv)\n",
    "    ssDout1 = Dropout(rate=0.5)(ssPool)\n",
    "    seqBiLstm = Bidirectional(LSTM(units = 128, return_sequences = True))(ssDout1)\n",
    "    seqDout2 = Dropout(rate = 0.5)(seqBiLstm)\n",
    "    ssFlat = Flatten()(seqDout2)\n",
    "    ssDen1 = Dense(256, kernel_initializer='glorot_uniform', activation=activation)(ssFlat)\n",
    "    ssDen1 = BatchNormalization()(ssDen1)\n",
    "    ssDout2 = Dropout(rate=0.5)(ssDen1)\n",
    "    den2 = Dense(256, kernel_initializer = 'glorot_uniform', activation='relu')(ssDout2)\n",
    "    den2 = BatchNormalization()(den2)\n",
    "    dout2 = Dropout(rate = 0.5)(den2)\n",
    "    den3 = Dense(256, activation='relu')(dout2)\n",
    "    dens = BatchNormalization()(den3)\n",
    "    den4 = Dense(3, activation = 'softmax')(den3)\n",
    "    model = Model(inputs = ssInput, outputs = den4)\n",
    "\n",
    "\n",
    "\n",
    "    adam = optimizers.Adam(lr=0.001)\n",
    "\n",
    "    if weights:\n",
    "        model.load_weights(weights)\n",
    "        print(\"Created model and loaded weights from file: \", weights)\n",
    "    else:\n",
    "        print(model.summary())\n",
    "        print(\"adam: 0.001\", )\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=adam,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 200, 4)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 189, 256)          12544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 189, 256)          1024      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 37, 256)           394240    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9472)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               2425088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 2,967,299\n",
      "Trainable params: 2,965,763\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "None\n",
      "adam: 0.001\n",
      "Train on 92757 samples, validate on 26502 samples\n",
      "Epoch 1/100\n",
      "92757/92757 [==============================] - 81s 877us/step - loss: 0.7075 - acc: 0.6938 - val_loss: 0.5783 - val_acc: 0.7530\n",
      "Epoch 2/100\n",
      "92757/92757 [==============================] - 78s 842us/step - loss: 0.5774 - acc: 0.7519 - val_loss: 0.5277 - val_acc: 0.7791\n",
      "Epoch 3/100\n",
      "92757/92757 [==============================] - 78s 844us/step - loss: 0.5363 - acc: 0.7690 - val_loss: 0.4989 - val_acc: 0.7849\n",
      "Epoch 4/100\n",
      "92757/92757 [==============================] - 78s 843us/step - loss: 0.5162 - acc: 0.7779 - val_loss: 0.5068 - val_acc: 0.7849\n",
      "Epoch 5/100\n",
      "92757/92757 [==============================] - 78s 842us/step - loss: 0.5029 - acc: 0.7852 - val_loss: 0.4942 - val_acc: 0.7849\n",
      "Epoch 6/100\n",
      "92757/92757 [==============================] - 78s 843us/step - loss: 0.4914 - acc: 0.7899 - val_loss: 0.4722 - val_acc: 0.7979\n",
      "Epoch 7/100\n",
      "92757/92757 [==============================] - 78s 843us/step - loss: 0.4828 - acc: 0.7934 - val_loss: 0.4722 - val_acc: 0.7989\n",
      "Epoch 8/100\n",
      "92757/92757 [==============================] - 78s 843us/step - loss: 0.4715 - acc: 0.7987 - val_loss: 0.4719 - val_acc: 0.7972\n",
      "Epoch 9/100\n",
      "92757/92757 [==============================] - 78s 841us/step - loss: 0.4623 - acc: 0.8022 - val_loss: 0.4676 - val_acc: 0.8007\n",
      "Epoch 10/100\n",
      "92757/92757 [==============================] - 78s 842us/step - loss: 0.4518 - acc: 0.8084 - val_loss: 0.4635 - val_acc: 0.8038\n",
      "Epoch 11/100\n",
      "92757/92757 [==============================] - 78s 844us/step - loss: 0.4444 - acc: 0.8107 - val_loss: 0.4673 - val_acc: 0.8023\n",
      "Epoch 12/100\n",
      "92757/92757 [==============================] - 78s 845us/step - loss: 0.4344 - acc: 0.8144 - val_loss: 0.4767 - val_acc: 0.7915\n",
      "Epoch 13/100\n",
      "92757/92757 [==============================] - 78s 845us/step - loss: 0.4262 - acc: 0.8180 - val_loss: 0.4664 - val_acc: 0.8011\n",
      "Epoch 14/100\n",
      "92757/92757 [==============================] - 78s 844us/step - loss: 0.4190 - acc: 0.8213 - val_loss: 0.4685 - val_acc: 0.8024\n",
      "Epoch 15/100\n",
      "92757/92757 [==============================] - 78s 845us/step - loss: 0.4121 - acc: 0.8238 - val_loss: 0.4604 - val_acc: 0.8073\n",
      "Epoch 16/100\n",
      "92757/92757 [==============================] - 78s 844us/step - loss: 0.4030 - acc: 0.8282 - val_loss: 0.4741 - val_acc: 0.8051\n",
      "Epoch 17/100\n",
      "92757/92757 [==============================] - 78s 845us/step - loss: 0.3981 - acc: 0.8294 - val_loss: 0.4773 - val_acc: 0.8030\n",
      "Epoch 18/100\n",
      "92757/92757 [==============================] - 78s 844us/step - loss: 0.3908 - acc: 0.8326 - val_loss: 0.4745 - val_acc: 0.8044\n",
      "Epoch 19/100\n",
      "92757/92757 [==============================] - 78s 844us/step - loss: 0.3840 - acc: 0.8353 - val_loss: 0.4798 - val_acc: 0.8066\n",
      "Epoch 20/100\n",
      "92757/92757 [==============================] - 78s 844us/step - loss: 0.3778 - acc: 0.8369 - val_loss: 0.4693 - val_acc: 0.8049\n",
      "Epoch 21/100\n",
      "92757/92757 [==============================] - 78s 846us/step - loss: 0.3595 - acc: 0.8448 - val_loss: 0.4758 - val_acc: 0.8083\n",
      "Epoch 22/100\n",
      "92757/92757 [==============================] - 78s 845us/step - loss: 0.3499 - acc: 0.8496 - val_loss: 0.4780 - val_acc: 0.8064\n",
      "Epoch 23/100\n",
      "92757/92757 [==============================] - 78s 844us/step - loss: 0.3430 - acc: 0.8526 - val_loss: 0.4845 - val_acc: 0.8063\n",
      "Epoch 24/100\n",
      "92757/92757 [==============================] - 78s 844us/step - loss: 0.3362 - acc: 0.8556 - val_loss: 0.4903 - val_acc: 0.8085\n",
      "Epoch 25/100\n",
      "92757/92757 [==============================] - 78s 844us/step - loss: 0.3306 - acc: 0.8583 - val_loss: 0.4846 - val_acc: 0.8074\n"
     ]
    }
   ],
   "source": [
    "weight_file = ''\n",
    "model = create_model()\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
    "filepath = weight_file + \"terminator.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(patience=5, factor=0.5)\n",
    "# load pretrained\n",
    "# model = load_model('terminator.hdf5')\n",
    "\n",
    "logs = model.fit(x_train, y_train, batch_size=128, verbose=1, epochs=100,\n",
    "          validation_data=(x_val, y_val),\n",
    "          callbacks=[checkpoint, early_stop, reduce_lr])\n",
    "    \n",
    "#     sys.stdout.write(strftime(\"%Y-%m-%d %H:%M:%S\") + \": Finished!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loss: 0.4679 - val_acc: 0.8073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('terminator.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 200, 4)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 189, 256)          12544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 189, 256)          1024      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 37, 256)           394240    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9472)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               2425088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 2,967,299\n",
      "Trainable params: 2,965,763\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26502, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26502, 200, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95     10491\n",
      "           1       0.69      0.33      0.45      5519\n",
      "           2       0.73      0.90      0.81     10492\n",
      "\n",
      "    accuracy                           0.81     26502\n",
      "   macro avg       0.78      0.73      0.73     26502\n",
      "weighted avg       0.80      0.81      0.79     26502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val)\n",
    "print(classification_report(np.argmax(y_val, axis=-1), np.argmax(y_pred, axis=-1), target_names=[str(i) for i in range(3)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10106    94   291]\n",
      " [  473  1837  3209]\n",
      " [  304   736  9452]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(np.argmax(y_val, axis=-1), np.argmax(y_pred, axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label = np.argmax(y_pred, axis=-1)\n",
    "y_val_label = np.argmax(y_val, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label[y_pred_label > 0] = 1\n",
    "y_val_label[y_val_label > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label = 1 - y_pred_label\n",
    "y_val_label = 1- y_val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96     16011\n",
      "           1       0.93      0.96      0.95     10491\n",
      "\n",
      "    accuracy                           0.96     26502\n",
      "   macro avg       0.95      0.96      0.95     26502\n",
      "weighted avg       0.96      0.96      0.96     26502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val_label, y_pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26502,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_label.shape, \n",
    "y_val_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivy(y_pred, y_true):\n",
    "    CM = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    return TP / (FN + TP)\n",
    "def acc(y_pred, y_true):\n",
    "    CM = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    \n",
    "    return sklearn.metrics.accuracy_score(y_true, y_pred), (TP + TN) / (TP + TN + FN + FP)\n",
    "def specificity(y_pred, y_true):\n",
    "    CM = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    return TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9561542525092446, 0.9561542525092446)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(y_pred_label, y_val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9633018778000191"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivy(y_pred_label, y_val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9514708637811504"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specificity(y_pred_label, y_val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
