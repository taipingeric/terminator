{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('dataset/raw/polyA_cs.fasta') as f:\n",
    "#     lines = f.readlines()\n",
    "#     for line in lines[:2]:\n",
    "#         print(line)\n",
    "#     print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in /opt/conda/lib/python3.6/site-packages (0.22.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "from textwrap import dedent\n",
    "from time import strftime\n",
    "from itertools import product\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Embedding, Bidirectional, Flatten, Dropout, GRU, Input, Conv1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for bases\n",
    "classes = {'A': 0,  # 0001\n",
    "         'T': 1,  # 0010\n",
    "         'C': 2,  # 0100\n",
    "         'G': 3,  # 1000 \n",
    "        }\n",
    "\n",
    "def fasta_to_vectors(in_fasta):\n",
    "    with open(in_fasta) as f:\n",
    "        header_seq = f.readlines()\n",
    "    \n",
    "    seq = [header_seq[i * 2 + 1].strip().upper() for i in range(int(len(header_seq)/2))] # extract seq data only\n",
    "    print(np.array(seq).shape)\n",
    "    for s in seq:\n",
    "        assert len(s) == 200\n",
    "        continue\n",
    "    \n",
    "    seqs = np.zeros((len(seq), 200, 1))\n",
    "    for i, s in enumerate(seq):\n",
    "        for j, char in enumerate(s):\n",
    "            seqs[i, j] = classes[char]\n",
    "    output = to_categorical(seqs, num_classes=len(classes))\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52457,)\n",
      "(27595,)\n",
      "(52460,)\n"
     ]
    }
   ],
   "source": [
    "lab1_fasta = '../dataset/raw/polyA_cs.fasta' # args.polya\n",
    "lab2_fasta = '../dataset/raw/non-polyA_cs.fasta' # args.cs\n",
    "lab3_fasta = '../dataset/raw/non-cs.fasta'\n",
    "l = 200\n",
    "\n",
    "k = np.array([4, 6, 8, 10])\n",
    "\n",
    "seq_vector_lab1 = np.array(fasta_to_vectors(lab1_fasta))\n",
    "seq_vector_lab2 = np.array(fasta_to_vectors(lab2_fasta))\n",
    "seq_vector_lab3 = np.array(fasta_to_vectors(lab3_fasta))\n",
    "lab_vector_lab1 = np.tile([1, 0, 0], (len(seq_vector_lab1), 1))\n",
    "lab_vector_lab2 = np.tile([0, 1, 0], (len(seq_vector_lab2), 1))\n",
    "lab_vector_lab3 = np.tile([0, 0, 1], (len(seq_vector_lab3), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the whole model\n",
    "random.seed(123)\n",
    "\n",
    "size1 = len(seq_vector_lab1)\n",
    "size2 = len(seq_vector_lab2)\n",
    "size3 = len(seq_vector_lab3)\n",
    "\n",
    "if size1 != size2 or size1 != size3:\n",
    "    train_i1 = random.sample(range(size1), int(0.7 * size1))\n",
    "    train_i2 = random.sample(range(size2), int(0.7 * size2))\n",
    "    train_i3 = random.sample(range(size3), int(0.7 * size3))\n",
    "\n",
    "else:\n",
    "    train_i1 = random.sample(range(size1), int(0.7 * size1))\n",
    "    train_i2 = train_i1\n",
    "    train_i3 = train_i1\n",
    "\n",
    "test_val1 = [i for i in range(size1) if i not in train_i1]\n",
    "val_i1 = random.sample(test_val1, int(0.2 * size1))\n",
    "\n",
    "test_val2 = [i for i in range(size2) if i not in train_i2]\n",
    "val_i2 = random.sample(test_val2, int(0.2 * size2))\n",
    "\n",
    "test_val3 = [i for i in range(size3) if i not in train_i3]\n",
    "val_i3 = random.sample(test_val3, int(0.2 * size3))\n",
    "\n",
    "x_train = np.concatenate((seq_vector_lab1[train_i1], seq_vector_lab2[train_i2], seq_vector_lab3[train_i3]))\n",
    "y_train = np.concatenate((lab_vector_lab1[train_i1], lab_vector_lab2[train_i2], lab_vector_lab3[train_i3]))\n",
    "x_val = np.concatenate((seq_vector_lab1[val_i1], seq_vector_lab2[val_i2], seq_vector_lab3[val_i3]))\n",
    "y_val = np.concatenate((lab_vector_lab1[val_i1], lab_vector_lab2[val_i2], lab_vector_lab3[val_i3]))\n",
    "\n",
    "#     sys.stdout.write(strftime(\"%Y-%m-%d %H:%M:%S\") + \": Start training\\n\")\n",
    "#     sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92757, 200, 4) (92757, 3) (26502, 200, 4) (26502, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(weights=''):\n",
    "    #activation = keras.layers.LeakyReLU(alpha=0.3)\n",
    "#     def activation(x):\n",
    "#         return keras.activations.relu(x)\n",
    "    activation = 'relu'\n",
    "    ssInput = Input(shape = (200, len(classes)))\n",
    "    ssConv = Conv1D(filters=256,\n",
    "                    kernel_size=12,\n",
    "                    padding = \"valid\",\n",
    "                    activation=activation,\n",
    "                    strides=1)(ssInput)\n",
    "#     ssConv = activation(ssConv)\n",
    "    ssPool = AveragePooling1D(pool_size = 5, strides = 5)(ssConv)\n",
    "    ssDout1 = Dropout(rate=0.5)(ssPool)\n",
    "    seqBiLstm = Bidirectional(LSTM(units = 128, return_sequences = True))(ssDout1)\n",
    "    seqDout2 = Dropout(rate = 0.5)(seqBiLstm)\n",
    "    ssFlat = Flatten()(seqDout2)\n",
    "    ssDen1 = Dense(256, kernel_initializer='glorot_uniform', activation=activation)(ssFlat)\n",
    "#     ssDen1 = activation(ssDen1)\n",
    "    ssDout2 = Dropout(rate=0.5)(ssDen1)\n",
    "    den2 = Dense(256, kernel_initializer = 'glorot_uniform', activation='relu')(ssDout2)\n",
    "#     den2 = activation(den2)\n",
    "    dout2 = Dropout(rate = 0.5)(den2)\n",
    "    den3 = Dense(256, activation='relu')(dout2)\n",
    "#     dens = activation(den3)\n",
    "    den4 = Dense(3, activation = 'softmax')(den3)\n",
    "    model = Model(inputs = ssInput, outputs = den4)\n",
    "\n",
    "\n",
    "\n",
    "    adam = optimizers.Adam(lr=0.001)\n",
    "\n",
    "    if weights:\n",
    "        model.load_weights(weights)\n",
    "        print(\"Created model and loaded weights from file: \", weights)\n",
    "    else:\n",
    "        print(model.summary())\n",
    "        print(\"adam: 0.001\", )\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=adam,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_file = ''\n",
    "model = create_model()\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
    "filepath = weight_file + \"terminator.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True)\n",
    "\n",
    "# load pretrained\n",
    "# model = load_model('terminator.hdf5')\n",
    "\n",
    "logs = model.fit(x_train, y_train, batch_size=128, verbose=1, epochs=100,\n",
    "          validation_data=(x_val, y_val),\n",
    "          callbacks=[checkpoint, early_stop])\n",
    "    \n",
    "#     sys.stdout.write(strftime(\"%Y-%m-%d %H:%M:%S\") + \": Finished!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loss: 0.4679 - val_acc: 0.8073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('terminator.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 200, 4)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 189, 256)          12544     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 37, 256)           394240    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 9472)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               2425088   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 2,873,219\n",
      "Trainable params: 2,873,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26502, 3)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26502, 200, 4)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     10491\n",
      "           1       0.76      0.23      0.36      5519\n",
      "           2       0.71      0.93      0.81     10492\n",
      "\n",
      "    accuracy                           0.80     26502\n",
      "   macro avg       0.80      0.71      0.70     26502\n",
      "weighted avg       0.80      0.80      0.77     26502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val)\n",
    "print(classification_report(np.argmax(y_val, axis=-1), np.argmax(y_pred, axis=-1), target_names=[str(i) for i in range(3)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10097    62   332]\n",
      " [  552  1290  3677]\n",
      " [  342   347  9803]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(np.argmax(y_val, axis=-1), np.argmax(y_pred, axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label = np.argmax(y_pred, axis=-1)\n",
    "y_val_label = np.argmax(y_val, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label[y_pred_label > 0] = 1\n",
    "y_val_label[y_val_label > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label = 1 - y_pred_label\n",
    "y_val_label = 1- y_val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96     16011\n",
      "           1       0.92      0.96      0.94     10491\n",
      "\n",
      "    accuracy                           0.95     26502\n",
      "   macro avg       0.95      0.95      0.95     26502\n",
      "weighted avg       0.95      0.95      0.95     26502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val_label, y_pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26502,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_label.shape, \n",
    "y_val_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivy(y_pred, y_true):\n",
    "    CM = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    return TP / (FN + TP)\n",
    "def acc(y_pred, y_true):\n",
    "    CM = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    \n",
    "    return sklearn.metrics.accuracy_score(y_true, y_pred), (TP + TN) / (TP + TN + FN + FP)\n",
    "def specificity(y_pred, y_true):\n",
    "    CM = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    return TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9513998943475964, 0.9513998943475964)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(y_pred_label, y_val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9624439996187208"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivy(y_pred_label, y_val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9441633876709762"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specificity(y_pred_label, y_val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
