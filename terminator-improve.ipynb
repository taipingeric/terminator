{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('dataset/raw/polyA_cs.fasta') as f:\n",
    "#     lines = f.readlines()\n",
    "#     for line in lines[:2]:\n",
    "#         print(line)\n",
    "#     print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in /opt/conda/lib/python3.6/site-packages (0.22.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn) (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "from textwrap import dedent\n",
    "from time import strftime\n",
    "from itertools import product\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Embedding, Bidirectional, Flatten, Dropout, GRU, Input, Conv1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for bases\n",
    "classes = {'A': 0,  # 0001\n",
    "         'T': 1,  # 0010\n",
    "         'C': 2,  # 0100\n",
    "         'G': 3,  # 1000 \n",
    "        }\n",
    "\n",
    "def fasta_to_vectors(in_fasta):\n",
    "    with open(in_fasta) as f:\n",
    "        header_seq = f.readlines()\n",
    "    \n",
    "    seq = [header_seq[i * 2 + 1].strip().upper() for i in range(int(len(header_seq)/2))] # extract seq data only\n",
    "    print(np.array(seq).shape)\n",
    "    for s in seq:\n",
    "        assert len(s) == 200\n",
    "        continue\n",
    "    \n",
    "    seqs = np.zeros((len(seq), 200, 1))\n",
    "    for i, s in enumerate(seq):\n",
    "        for j, char in enumerate(s):\n",
    "            seqs[i, j] = classes[char]\n",
    "    output = to_categorical(seqs, num_classes=len(classes))\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52457,)\n",
      "(27595,)\n",
      "(52460,)\n"
     ]
    }
   ],
   "source": [
    "lab1_fasta = '../dataset/raw/polyA_cs.fasta' # args.polya\n",
    "lab2_fasta = '../dataset/raw/non-polyA_cs.fasta' # args.cs\n",
    "lab3_fasta = '../dataset/raw/non-cs.fasta'\n",
    "l = 200\n",
    "\n",
    "k = np.array([4, 6, 8, 10])\n",
    "\n",
    "seq_vector_lab1 = np.array(fasta_to_vectors(lab1_fasta))\n",
    "seq_vector_lab2 = np.array(fasta_to_vectors(lab2_fasta))\n",
    "seq_vector_lab3 = np.array(fasta_to_vectors(lab3_fasta))\n",
    "lab_vector_lab1 = np.tile([1, 0, 0], (len(seq_vector_lab1), 1))\n",
    "lab_vector_lab2 = np.tile([0, 1, 0], (len(seq_vector_lab2), 1))\n",
    "lab_vector_lab3 = np.tile([0, 0, 1], (len(seq_vector_lab3), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the whole model\n",
    "random.seed(123)\n",
    "\n",
    "size1 = len(seq_vector_lab1)\n",
    "size2 = len(seq_vector_lab2)\n",
    "size3 = len(seq_vector_lab3)\n",
    "\n",
    "if size1 != size2 or size1 != size3:\n",
    "    train_i1 = random.sample(range(size1), int(0.7 * size1))\n",
    "    train_i2 = random.sample(range(size2), int(0.7 * size2))\n",
    "    train_i3 = random.sample(range(size3), int(0.7 * size3))\n",
    "\n",
    "else:\n",
    "    train_i1 = random.sample(range(size1), int(0.7 * size1))\n",
    "    train_i2 = train_i1\n",
    "    train_i3 = train_i1\n",
    "\n",
    "test_val1 = [i for i in range(size1) if i not in train_i1]\n",
    "val_i1 = random.sample(test_val1, int(0.2 * size1))\n",
    "\n",
    "test_val2 = [i for i in range(size2) if i not in train_i2]\n",
    "val_i2 = random.sample(test_val2, int(0.2 * size2))\n",
    "\n",
    "test_val3 = [i for i in range(size3) if i not in train_i3]\n",
    "val_i3 = random.sample(test_val3, int(0.2 * size3))\n",
    "\n",
    "x_train = np.concatenate((seq_vector_lab1[train_i1], seq_vector_lab2[train_i2], seq_vector_lab3[train_i3]))\n",
    "y_train = np.concatenate((lab_vector_lab1[train_i1], lab_vector_lab2[train_i2], lab_vector_lab3[train_i3]))\n",
    "x_val = np.concatenate((seq_vector_lab1[val_i1], seq_vector_lab2[val_i2], seq_vector_lab3[val_i3]))\n",
    "y_val = np.concatenate((lab_vector_lab1[val_i1], lab_vector_lab2[val_i2], lab_vector_lab3[val_i3]))\n",
    "\n",
    "#     sys.stdout.write(strftime(\"%Y-%m-%d %H:%M:%S\") + \": Start training\\n\")\n",
    "#     sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92757, 200, 4) (92757, 3) (26502, 200, 4) (26502, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(weights=''):\n",
    "    ssInput = Input(shape = (200, len(classes)))\n",
    "    ssConv = Conv1D(filters=256,\n",
    "                    kernel_size=12,\n",
    "                    padding = \"valid\",\n",
    "                    activation=\"relu\",\n",
    "                    strides=1)(ssInput)\n",
    "    ssPool = AveragePooling1D(pool_size = 5, strides = 5)(ssConv)\n",
    "    ssDout1 = Dropout(rate=0.7)(ssPool)\n",
    "    seqBiLstm = Bidirectional(LSTM(units = 128, return_sequences = True))(ssDout1)\n",
    "    seqDout2 = Dropout(rate = 0.7)(seqBiLstm)\n",
    "    ssFlat = Flatten()(seqDout2)\n",
    "    ssDen1 = Dense(256, kernel_initializer='glorot_uniform', activation = 'relu')(ssFlat)\n",
    "    ssDout2 = Dropout(rate=0.7)(ssDen1)\n",
    "    den2 = Dense(128, kernel_initializer = 'glorot_uniform', activation = 'relu')(ssDout2)\n",
    "    dout2 = Dropout(rate = 0.7)(den2)\n",
    "    den3 = Dense(64, activation = 'relu')(dout2)\n",
    "    den4 = Dense(3, activation = 'softmax')(den3)\n",
    "    model = Model(inputs = ssInput, outputs = den4)\n",
    "\n",
    "\n",
    "\n",
    "    adam = optimizers.Adam(lr=0.001)\n",
    "\n",
    "    if weights:\n",
    "        model.load_weights(weights)\n",
    "        print(\"Created model and loaded weights from file: \", weights)\n",
    "    else:\n",
    "        print(model.summary())\n",
    "        print(\"adam: 0.001\", )\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=adam,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 200, 4)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 189, 256)          12544     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_7 (Average (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 37, 256)           394240    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 9472)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               2425088   \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 2,873,219\n",
      "Trainable params: 2,873,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "adam: 0.001\n",
      "Train on 92757 samples, validate on 26502 samples\n",
      "Epoch 1/100\n",
      "92757/92757 [==============================] - 75s 806us/step - loss: 0.5206 - acc: 0.7779 - val_loss: 0.5040 - val_acc: 0.7861\n",
      "Epoch 2/100\n",
      "92757/92757 [==============================] - 73s 782us/step - loss: 0.5186 - acc: 0.7786 - val_loss: 0.5030 - val_acc: 0.7811\n",
      "Epoch 3/100\n",
      "92757/92757 [==============================] - 73s 782us/step - loss: 0.5149 - acc: 0.7805 - val_loss: 0.4979 - val_acc: 0.7880\n",
      "Epoch 4/100\n",
      "92757/92757 [==============================] - 73s 783us/step - loss: 0.5139 - acc: 0.7806 - val_loss: 0.5077 - val_acc: 0.7842\n",
      "Epoch 5/100\n",
      "92757/92757 [==============================] - 73s 784us/step - loss: 0.5153 - acc: 0.7799 - val_loss: 0.5073 - val_acc: 0.7861\n",
      "Epoch 6/100\n",
      "92757/92757 [==============================] - 73s 785us/step - loss: 0.5119 - acc: 0.7820 - val_loss: 0.4996 - val_acc: 0.7897\n",
      "Epoch 7/100\n",
      "92757/92757 [==============================] - 73s 783us/step - loss: 0.5113 - acc: 0.7827 - val_loss: 0.5002 - val_acc: 0.7905\n",
      "Epoch 8/100\n",
      "92757/92757 [==============================] - 73s 783us/step - loss: 0.5101 - acc: 0.7826 - val_loss: 0.4904 - val_acc: 0.7910\n",
      "Epoch 9/100\n",
      "92757/92757 [==============================] - 73s 785us/step - loss: 0.5082 - acc: 0.7833 - val_loss: 0.4982 - val_acc: 0.7850\n",
      "Epoch 10/100\n",
      "92757/92757 [==============================] - 73s 783us/step - loss: 0.5103 - acc: 0.7838 - val_loss: 0.4960 - val_acc: 0.7848\n",
      "Epoch 11/100\n",
      "92757/92757 [==============================] - 73s 782us/step - loss: 0.5072 - acc: 0.7838 - val_loss: 0.5044 - val_acc: 0.7857\n",
      "Epoch 12/100\n",
      "92757/92757 [==============================] - 73s 783us/step - loss: 0.5039 - acc: 0.7859 - val_loss: 0.4893 - val_acc: 0.7934\n",
      "Epoch 13/100\n",
      "92757/92757 [==============================] - 73s 783us/step - loss: 0.5046 - acc: 0.7863 - val_loss: 0.5013 - val_acc: 0.7883\n",
      "Epoch 14/100\n",
      "92757/92757 [==============================] - 72s 782us/step - loss: 0.5031 - acc: 0.7852 - val_loss: 0.4888 - val_acc: 0.7919\n",
      "Epoch 15/100\n",
      "92757/92757 [==============================] - 73s 784us/step - loss: 0.5033 - acc: 0.7851 - val_loss: 0.4897 - val_acc: 0.7941\n",
      "Epoch 16/100\n",
      "92757/92757 [==============================] - 73s 782us/step - loss: 0.5002 - acc: 0.7863 - val_loss: 0.4857 - val_acc: 0.7919\n",
      "Epoch 17/100\n",
      "92757/92757 [==============================] - 73s 785us/step - loss: 0.5002 - acc: 0.7869 - val_loss: 0.4797 - val_acc: 0.7970\n",
      "Epoch 18/100\n",
      "92757/92757 [==============================] - 73s 784us/step - loss: 0.4978 - acc: 0.7885 - val_loss: 0.4871 - val_acc: 0.7936\n",
      "Epoch 19/100\n",
      "92757/92757 [==============================] - 73s 782us/step - loss: 0.4962 - acc: 0.7889 - val_loss: 0.4855 - val_acc: 0.7917\n",
      "Epoch 20/100\n",
      "92757/92757 [==============================] - 73s 783us/step - loss: 0.4966 - acc: 0.7892 - val_loss: 0.4852 - val_acc: 0.7918\n",
      "Epoch 21/100\n",
      "92757/92757 [==============================] - 73s 782us/step - loss: 0.4958 - acc: 0.7899 - val_loss: 0.4802 - val_acc: 0.7953\n",
      "Epoch 22/100\n",
      "92757/92757 [==============================] - 73s 786us/step - loss: 0.4921 - acc: 0.7911 - val_loss: 0.4860 - val_acc: 0.7883\n",
      "Epoch 23/100\n",
      "92757/92757 [==============================] - 73s 784us/step - loss: 0.4927 - acc: 0.7899 - val_loss: 0.4944 - val_acc: 0.7908\n",
      "Epoch 24/100\n",
      "92757/92757 [==============================] - 73s 783us/step - loss: 0.4924 - acc: 0.7910 - val_loss: 0.4812 - val_acc: 0.7946\n",
      "Epoch 25/100\n",
      "92757/92757 [==============================] - 73s 783us/step - loss: 0.4903 - acc: 0.7919 - val_loss: 0.4764 - val_acc: 0.7978\n",
      "Epoch 26/100\n",
      "92757/92757 [==============================] - 73s 784us/step - loss: 0.4926 - acc: 0.7915 - val_loss: 0.4797 - val_acc: 0.7963\n",
      "Epoch 27/100\n",
      "92757/92757 [==============================] - 73s 783us/step - loss: 0.4891 - acc: 0.7915 - val_loss: 0.4725 - val_acc: 0.7996\n",
      "Epoch 28/100\n",
      "92757/92757 [==============================] - 73s 784us/step - loss: 0.4889 - acc: 0.7942 - val_loss: 0.4771 - val_acc: 0.7981\n",
      "Epoch 29/100\n",
      "92757/92757 [==============================] - 73s 784us/step - loss: 0.4866 - acc: 0.7924 - val_loss: 0.4788 - val_acc: 0.7945\n",
      "Epoch 30/100\n",
      "92757/92757 [==============================] - 73s 785us/step - loss: 0.4876 - acc: 0.7938 - val_loss: 0.4742 - val_acc: 0.7959\n",
      "Epoch 31/100\n",
      "92757/92757 [==============================] - 73s 782us/step - loss: 0.4866 - acc: 0.7925 - val_loss: 0.4758 - val_acc: 0.7975\n",
      "Epoch 32/100\n",
      "92757/92757 [==============================] - 73s 786us/step - loss: 0.4846 - acc: 0.7945 - val_loss: 0.4769 - val_acc: 0.7979\n",
      "Epoch 33/100\n",
      "92757/92757 [==============================] - 73s 785us/step - loss: 0.4830 - acc: 0.7939 - val_loss: 0.4755 - val_acc: 0.7955\n",
      "Epoch 34/100\n",
      "92757/92757 [==============================] - 73s 783us/step - loss: 0.4835 - acc: 0.7958 - val_loss: 0.4729 - val_acc: 0.7969\n",
      "Epoch 35/100\n",
      "92757/92757 [==============================] - 73s 783us/step - loss: 0.4819 - acc: 0.7963 - val_loss: 0.4794 - val_acc: 0.7964\n",
      "Epoch 36/100\n",
      "92757/92757 [==============================] - 73s 783us/step - loss: 0.4806 - acc: 0.7950 - val_loss: 0.4754 - val_acc: 0.7985\n",
      "Epoch 37/100\n",
      "92757/92757 [==============================] - 73s 782us/step - loss: 0.4800 - acc: 0.7958 - val_loss: 0.4737 - val_acc: 0.7983\n"
     ]
    }
   ],
   "source": [
    "weight_file = ''\n",
    "model = create_model()\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
    "filepath = weight_file + \"terminator.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True)\n",
    "\n",
    "# load pretrained\n",
    "model = load_model('terminator.hdf5')\n",
    "\n",
    "logs = model.fit(x_train, y_train, batch_size=128, verbose=1, epochs=100,\n",
    "          validation_data=(x_val, y_val),\n",
    "          callbacks=[checkpoint, early_stop])\n",
    "    \n",
    "#     sys.stdout.write(strftime(\"%Y-%m-%d %H:%M:%S\") + \": Finished!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_loss: 0.4679 - val_acc: 0.8073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('terminator.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 200, 4)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 189, 256)          12544     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 37, 256)           394240    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 9472)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               2425088   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 2,873,219\n",
      "Trainable params: 2,873,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26502, 3)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26502, 200, 4)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     10491\n",
      "           1       0.76      0.23      0.36      5519\n",
      "           2       0.71      0.93      0.81     10492\n",
      "\n",
      "    accuracy                           0.80     26502\n",
      "   macro avg       0.80      0.71      0.70     26502\n",
      "weighted avg       0.80      0.80      0.77     26502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val)\n",
    "print(classification_report(np.argmax(y_val, axis=-1), np.argmax(y_pred, axis=-1), target_names=[str(i) for i in range(3)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10097    62   332]\n",
      " [  552  1290  3677]\n",
      " [  342   347  9803]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(np.argmax(y_val, axis=-1), np.argmax(y_pred, axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label = np.argmax(y_pred, axis=-1)\n",
    "y_val_label = np.argmax(y_val, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label[y_pred_label > 0] = 1\n",
    "y_val_label[y_val_label > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_label = 1 - y_pred_label\n",
    "y_val_label = 1- y_val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96     16011\n",
      "           1       0.92      0.96      0.94     10491\n",
      "\n",
      "    accuracy                           0.95     26502\n",
      "   macro avg       0.95      0.95      0.95     26502\n",
      "weighted avg       0.95      0.95      0.95     26502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val_label, y_pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26502,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_label.shape, \n",
    "y_val_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivy(y_pred, y_true):\n",
    "    CM = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    return TP / (FN + TP)\n",
    "def acc(y_pred, y_true):\n",
    "    CM = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    \n",
    "    return sklearn.metrics.accuracy_score(y_true, y_pred), (TP + TN) / (TP + TN + FN + FP)\n",
    "def specificity(y_pred, y_true):\n",
    "    CM = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    return TN/(TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9513998943475964, 0.9513998943475964)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(y_pred_label, y_val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9624439996187208"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivy(y_pred_label, y_val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9441633876709762"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specificity(y_pred_label, y_val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
